{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import streamlit as st\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "import kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/ravirajsinh45/real-life-industrial-dataset-of-casting-product\n"
     ]
    }
   ],
   "source": [
    "kaggle.api.authenticate()\n",
    "dataset_url = 'ravirajsinh45/real-life-industrial-dataset-of-casting-product'\n",
    "kaggle.api.dataset_download_files(dataset_url, unzip=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rotation_range = 360,\n",
    "                                     width_shift_range = 0.05,\n",
    "                                     height_shift_range = 0.05,\n",
    "                                     shear_range = 0.05,\n",
    "                                     zoom_range = 0.05,\n",
    "                                     horizontal_flip = True,\n",
    "                                     vertical_flip = True,\n",
    "                                     brightness_range = [0.75, 1.25],\n",
    "                                     rescale = 1./255,\n",
    "                                     validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5307 images belonging to 2 classes.\n",
      "Found 1326 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# get data \n",
    "#menentukan satu set nilai lain untuk parameter 'flow_from_directory':\n",
    "IMAGE_DIR = \"./casting_data/casting_data/\"\n",
    "IMAGE_SIZE = (300, 300)\n",
    "BATCH_SIZE = 64\n",
    "SEED_NUMBER = 123\n",
    "\n",
    "gen_args = dict(target_size = IMAGE_SIZE,\n",
    "                color_mode = \"grayscale\",\n",
    "                batch_size = BATCH_SIZE,\n",
    "                class_mode = \"binary\",\n",
    "                classes = {\"ok_front\": 0, \"def_front\": 1},\n",
    "                seed = SEED_NUMBER)\n",
    "\n",
    "train_dataset = train_generator.flow_from_directory(\n",
    "                                        directory = IMAGE_DIR + \"train\",\n",
    "                                        subset = \"training\", shuffle = True, **gen_args)\n",
    "validation_dataset = train_generator.flow_from_directory(\n",
    "                                        directory = IMAGE_DIR + \"train\",\n",
    "                                        subset = \"validation\", shuffle = True, **gen_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'normal', 1: 'defect'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_class = {0: \"normal\", 1: \"defect\"}\n",
    "mapping_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeImageBatch(dataset, title):\n",
    "    images, labels = next(iter(dataset))\n",
    "    images = images.reshape(BATCH_SIZE, *IMAGE_SIZE)\n",
    "    fig, axes = plt.subplots(8, 8, figsize=(16,16))\n",
    "\n",
    "    for ax, img, label in zip(axes.flat, images, labels):\n",
    "        ax.imshow(img, cmap = \"gray\")\n",
    "        ax.axis(\"off\")\n",
    "        ax.set_title(mapping_class[label], size = 20)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.suptitle(title, size = 30, y = 1.05, fontweight = \"bold\")\n",
    "    plt.show()\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 21:11:16.725136: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, strides=2, activation=\"relu\", input_shape=IMAGE_SIZE + (1, )))\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "model.add(Conv2D(filters=16, kernel_size=3, strides=2, activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 149, 149, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 36, 36, 16)        4624      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 18, 18, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 5184)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               663680    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 676,945\n",
      "Trainable params: 676,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 21:11:32.566952: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - ETA: 0s - loss: 0.6761 - accuracy: 0.5775"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 21:13:49.337806: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.61928, saving model to model/cnn_casting_inspection_model.keras\n",
      "83/83 [==============================] - 158s 2s/step - loss: 0.6761 - accuracy: 0.5775 - val_loss: 0.6193 - val_accuracy: 0.6463\n",
      "Epoch 2/10\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.6053 - accuracy: 0.6593\n",
      "Epoch 2: val_loss improved from 0.61928 to 0.53944, saving model to model/cnn_casting_inspection_model.keras\n",
      "83/83 [==============================] - 163s 2s/step - loss: 0.6053 - accuracy: 0.6593 - val_loss: 0.5394 - val_accuracy: 0.7391\n",
      "Epoch 3/10\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.5057 - accuracy: 0.7398\n",
      "Epoch 3: val_loss improved from 0.53944 to 0.43658, saving model to model/cnn_casting_inspection_model.keras\n",
      "83/83 [==============================] - 149s 2s/step - loss: 0.5057 - accuracy: 0.7398 - val_loss: 0.4366 - val_accuracy: 0.8122\n",
      "Epoch 4/10\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.4256 - accuracy: 0.7969\n",
      "Epoch 4: val_loss improved from 0.43658 to 0.37402, saving model to model/cnn_casting_inspection_model.keras\n",
      "83/83 [==============================] - 146s 2s/step - loss: 0.4256 - accuracy: 0.7969 - val_loss: 0.3740 - val_accuracy: 0.8333\n",
      "Epoch 5/10\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.3405 - accuracy: 0.8525\n",
      "Epoch 5: val_loss improved from 0.37402 to 0.29959, saving model to model/cnn_casting_inspection_model.keras\n",
      "83/83 [==============================] - 148s 2s/step - loss: 0.3405 - accuracy: 0.8525 - val_loss: 0.2996 - val_accuracy: 0.8544\n",
      "Epoch 6/10\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.2680 - accuracy: 0.8884\n",
      "Epoch 6: val_loss improved from 0.29959 to 0.26376, saving model to model/cnn_casting_inspection_model.keras\n",
      "83/83 [==============================] - 145s 2s/step - loss: 0.2680 - accuracy: 0.8884 - val_loss: 0.2638 - val_accuracy: 0.8756\n",
      "Epoch 7/10\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.2319 - accuracy: 0.9056\n",
      "Epoch 7: val_loss improved from 0.26376 to 0.18443, saving model to model/cnn_casting_inspection_model.keras\n",
      "83/83 [==============================] - 174s 2s/step - loss: 0.2319 - accuracy: 0.9056 - val_loss: 0.1844 - val_accuracy: 0.9246\n",
      "Epoch 8/10\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.2013 - accuracy: 0.9178\n",
      "Epoch 8: val_loss improved from 0.18443 to 0.16529, saving model to model/cnn_casting_inspection_model.keras\n",
      "83/83 [==============================] - 171s 2s/step - loss: 0.2013 - accuracy: 0.9178 - val_loss: 0.1653 - val_accuracy: 0.9359\n",
      "Epoch 9/10\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1744 - accuracy: 0.9308\n",
      "Epoch 9: val_loss improved from 0.16529 to 0.11561, saving model to model/cnn_casting_inspection_model.keras\n",
      "83/83 [==============================] - 199s 2s/step - loss: 0.1744 - accuracy: 0.9308 - val_loss: 0.1156 - val_accuracy: 0.9548\n",
      "Epoch 10/10\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.1525 - accuracy: 0.9438\n",
      "Epoch 10: val_loss improved from 0.11561 to 0.11341, saving model to model/cnn_casting_inspection_model.keras\n",
      "83/83 [==============================] - 422s 5s/step - loss: 0.1525 - accuracy: 0.9438 - val_loss: 0.1134 - val_accuracy: 0.9623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd2bee2d810>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('model/cnn_casting_inspection_model.keras', verbose=1, save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "model.fit(train_dataset, validation_data=validation_dataset, batch_size=16, epochs=10, callbacks=[checkpoint], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 21:47:09.306242: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-05-27 21:47:09.380997: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-05-27 21:47:11.038871: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-05-27 21:47:11.268573: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,64]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/taufiqu/Capstone37/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/taufiqu/Capstone37/assets\n"
     ]
    }
   ],
   "source": [
    "tf.keras.models.save_model(model,'/home/taufiqu/Capstone37')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
